{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, isdir, join\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import math\n",
    "#import argparse\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "#mnist = input_data.read_data_sets('MNSIT_data',one_hot=True)\n",
    "\n",
    "def rotate(image, angle, center=None, scale=1.0):\n",
    "    # 獲取圖像尺寸\n",
    "    (h, w) = image.shape[:2]\n",
    "    # 若未指定旋轉中心，则將圖像中心設為旋轉中心\n",
    "    if center is None:\n",
    "        center = (w / 2, h / 2)\n",
    "    # 執行旋轉\n",
    "    M = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h))\n",
    "    # 返回旋轉後的圖像\n",
    "    return rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##將cvs裡面答案轉為陣列\n",
    "df = pd.read_csv('validation.csv',header=None)  \n",
    "df = df.T\n",
    "df_temp = pd.get_dummies(df[0]) #One-hot編碼\n",
    "y_r = np.array(df_temp)\n",
    "##將驗證圖片讀檔，二值化並存成2維陣列200*(784)\n",
    "img_set = []\n",
    "\n",
    "#img_merge = np.zeros((20*28,10*28))#組合商品圖為一張，方便看\n",
    "\n",
    "# 指定要列出所有檔案的目錄\n",
    "mypath = \"./validation\"\n",
    "# 取得所有檔案與子目錄名稱\n",
    "files = listdir(mypath)\n",
    "# 以迴圈處理\n",
    "j=0\n",
    "size = 28\n",
    "for i,f in enumerate(files):\n",
    "    # 產生檔案的絕對路徑\n",
    "    fullpath = join(mypath, f)\n",
    "    #print(f)\n",
    "    # 判斷 fullpath 是檔案還是目錄\n",
    "    ro = False\n",
    "    if isfile(fullpath):\n",
    "        im = cv2.imread(fullpath,0)\n",
    "        image = cv2.imread(fullpath)\n",
    "        #img_merge[j%20*28:j%20*28+28,j//20*28: j//20*28+28]=im\n",
    "        retval, im_bin = cv2.threshold(im,215, 255, cv2.THRESH_BINARY_INV)\n",
    "        retval, labels,stats,centroids = cv2.connectedComponentsWithStats(im_bin)\n",
    "        x,y,w,h,area=stats[1]\n",
    "        cx,cy = centroids[1]\n",
    "\n",
    "        if w<5:\n",
    "            x=math.ceil(cx-3)\n",
    "            w=w+4\n",
    "        if h<5 :\n",
    "            y=math.ceil(cy-3)\n",
    "            h=h+6\n",
    "        if w > h+1 and w >10 :\n",
    "            #ro= True\n",
    "            img = rotate(im,90)\n",
    "            crop_img = img[x-1:x+w+1,y-1:y+h+1]\n",
    "        else:\n",
    "            crop_img = im[y:y+h,x:x+w]\n",
    "        im_h ,im_w= crop_img.shape\n",
    "        r = int(min(24/im_w,24/im_h))\n",
    "        if r<=0: r=1\n",
    "        if r>=4:r=2\n",
    "        crop_img = cv2.resize(crop_img,(im_w*r,im_h*r),interpolation=cv2.INTER_AREA)#interpolation=cv2.INTER_NEAREST\n",
    "        im_h ,im_w= crop_img.shape\n",
    "        u = int((size-im_h)/2)\n",
    "        v = int((size-im_w)/2)\n",
    "        crop_img = cv2.copyMakeBorder(crop_img,u,size-im_h-u,v,size-im_w-v, cv2.BORDER_CONSTANT,value=[255,255,255])\n",
    "        crop_img = cv2.erode(crop_img,(3,3), iterations=1)\n",
    "        #cv2.imwrite('./Desktop/new/'+f,crop_img)\n",
    "        \n",
    "        img = np.array(crop_img,dtype=np.float32).reshape(28,28,1)\n",
    "        img_set.append(1-img/255)\n",
    "img_set= np.array(img_set)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 800)               2509600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                8010      \n",
      "=================================================================\n",
      "Total params: 2,569,706\n",
      "Trainable params: 2,569,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 150\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "import keras\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Build the neural network! \n",
    "model = Sequential() \n",
    "# First convolutional layer with max pooling \n",
    "model.add(Conv2D(32, (5, 5), padding=\"same\", input_shape=(28, 28, 1), activation=\"relu\")) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2))) \n",
    "# Second convolutional layer with max pooling \n",
    "model.add(Conv2D(64, (5, 5), padding=\"same\", activation=\"relu\")) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2))) \n",
    "# Hidden layer with 500 nodes \n",
    "model.add(Flatten()) \n",
    "model.add(Dense(800, activation=\"relu\")) \n",
    "# Output layer with 10 nodes (one for each possible letter/number we predict) \n",
    "model.add(Dense(10, activation=\"softmax\")) \n",
    "# Ask Keras to build the TensorFlow model behind the scenes \n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "X_train = x_train.reshape(60000,28,28,1)/255\n",
    "X_test = x_test.reshape(10000,28,28,1)/255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 200 samples\n",
      "Epoch 1/25\n",
      "5000/5000 [==============================] - 5s 971us/step - loss: 0.8058 - accuracy: 0.7560 - val_loss: 0.2112 - val_accuracy: 0.9500\n",
      "Epoch 2/25\n",
      "5000/5000 [==============================] - 5s 926us/step - loss: 0.1856 - accuracy: 0.9452 - val_loss: 0.0807 - val_accuracy: 0.9850\n",
      "Epoch 3/25\n",
      "5000/5000 [==============================] - 5s 984us/step - loss: 0.1036 - accuracy: 0.9708 - val_loss: 0.0675 - val_accuracy: 0.9800\n",
      "Epoch 4/25\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.0673 - accuracy: 0.9806 - val_loss: 0.0307 - val_accuracy: 0.9900\n",
      "Epoch 5/25\n",
      "5000/5000 [==============================] - 5s 935us/step - loss: 0.0490 - accuracy: 0.9868 - val_loss: 0.0257 - val_accuracy: 0.9950\n",
      "Epoch 6/25\n",
      "5000/5000 [==============================] - 5s 954us/step - loss: 0.0314 - accuracy: 0.9924 - val_loss: 0.0189 - val_accuracy: 0.9950\n",
      "Epoch 7/25\n",
      "5000/5000 [==============================] - 5s 945us/step - loss: 0.0244 - accuracy: 0.9930 - val_loss: 0.0199 - val_accuracy: 0.9950\n",
      "Epoch 8/25\n",
      "5000/5000 [==============================] - 5s 956us/step - loss: 0.0156 - accuracy: 0.9956 - val_loss: 0.0184 - val_accuracy: 0.9950\n",
      "Epoch 9/25\n",
      "5000/5000 [==============================] - 5s 942us/step - loss: 0.0139 - accuracy: 0.9960 - val_loss: 0.0214 - val_accuracy: 0.9900\n",
      "Epoch 10/25\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.0336 - val_accuracy: 0.9850\n",
      "Epoch 11/25\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.0156 - val_accuracy: 0.9950\n",
      "Epoch 12/25\n",
      "5000/5000 [==============================] - 5s 964us/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 13/25\n",
      "5000/5000 [==============================] - 5s 969us/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
      "Epoch 14/25\n",
      "5000/5000 [==============================] - 5s 959us/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.0186 - val_accuracy: 0.9900\n",
      "Epoch 15/25\n",
      "5000/5000 [==============================] - 5s 963us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
      "Epoch 16/25\n",
      "5000/5000 [==============================] - 5s 960us/step - loss: 8.6146e-04 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 17/25\n",
      "5000/5000 [==============================] - 5s 973us/step - loss: 4.3551e-04 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 18/25\n",
      "5000/5000 [==============================] - 5s 978us/step - loss: 2.7477e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 19/25\n",
      "5000/5000 [==============================] - 5s 971us/step - loss: 2.2637e-04 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 20/25\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 2.0016e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 21/25\n",
      "5000/5000 [==============================] - 5s 986us/step - loss: 1.7342e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 22/25\n",
      "5000/5000 [==============================] - 5s 985us/step - loss: 1.6029e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 23/25\n",
      "5000/5000 [==============================] - 5s 950us/step - loss: 1.4251e-04 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 24/25\n",
      "5000/5000 [==============================] - 5s 954us/step - loss: 1.3097e-04 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 25/25\n",
      "5000/5000 [==============================] - 5s 967us/step - loss: 1.2283e-04 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2339a5dc388>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the neural network \n",
    "model.fit(X_train[0:5000], y_train[0:5000], validation_data=(X_test[0:200], y_test[0:200]), batch_size=batch_size, epochs=25, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 7 8 8 1 1 3 4 4 5 5 6 6 3 2 2 1 1 0 0 7 0 8 8 2 3 3 8 4 5 5 6 6 0 3 3 1\n",
      " 2 4 3 0 0 1 1 7 2 3 4 6 5 5 4 4 3 9 9 8 1 8 0 9 6 3 6 7 9 5 2 2 1 4 1 1 9\n",
      " 1 0 4 7 7 3 0 6 3 4 6 2 8 5 2 9 9 1 8 4 1 1 7 7 6 0 7 7 5 0 4 3 4 4 4 4 4\n",
      " 4 0 2 1 6 1 1 0 1 9 4 3 0 4 5 7 0 3 3 2 4 4 8 5 6 6 9 9 8 8 8 8 8 8 8 8 8\n",
      " 8 7 7 8 8 6 6 5 5 4 4 3 3 2 2 1 1 1 0 9 1 6 6 8 4 9 9 2 1 5 8 9 4 1 3 8 7\n",
      " 7 3 3 4 3 2 3 6 2 3 5 2 3 3 6]\n",
      "Testing Accuracy: 0.68\n"
     ]
    }
   ],
   "source": [
    "result = model.predict_classes(img_set)\n",
    "print(result)\n",
    "score = 0\n",
    "for pre,ans in zip(list(result),list(np.array(df[0]))): \n",
    "    if pre ==ans:\n",
    "        score=score+1\n",
    "    else:pass\n",
    "print(\"Testing Accuracy:\",score/200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
