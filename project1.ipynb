{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, isdir, join\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import math\n",
    "#import argparse\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "#mnist = input_data.read_data_sets('MNSIT_data',one_hot=True)\n",
    "\n",
    "def rotate(image, angle, center=None, scale=1.0):\n",
    "    # 獲取圖像尺寸\n",
    "    (h, w) = image.shape[:2]\n",
    "    # 若未指定旋轉中心，则將圖像中心設為旋轉中心\n",
    "    if center is None:\n",
    "        center = (w / 2, h / 2)\n",
    "    # 執行旋轉\n",
    "    M = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h))\n",
    "    # 返回旋轉後的圖像\n",
    "    return rotated\n",
    "\n",
    "def compute_accuracy(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction, feed_dict={xs: v_xs, keep_prob: 1})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    result = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys, keep_prob: 1})\n",
    "    return result\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1) #類似normal分布，產生隨機變量\n",
    "    return tf.Variable(initial)\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "def conv2d(x,W):\n",
    "    #stride [1,x_movement,y_movement,1],頭尾一定都是1\n",
    "    #Must have strides[0]=strides[3]=1\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding = 'SAME') \n",
    "def max_pool_2x2(x):\n",
    "    #stride [1,x_movement,y_movement,1]\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "batch_size = 150\n",
    "#batch_xs,batch_ys= mnist.train.next_batch(batch_size)\n",
    "#print(batch_xs)\n",
    "#print(batch_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "##將cvs裡面答案轉為陣列\n",
    "df = pd.read_csv('validation.csv',header=None)  \n",
    "df = df.T\n",
    "df_temp = pd.get_dummies(df[0]) #One-hot編碼\n",
    "y_r = np.array(df_temp)\n",
    "##將驗證圖片讀檔，二值化並存成2維陣列200*(784)\n",
    "img_set = np.zeros((200,28*28))\n",
    "\n",
    "img_merge = np.zeros((20*28,10*28))\n",
    "# 指定要列出所有檔案的目錄\n",
    "mypath = \"./validation\"\n",
    "# 取得所有檔案與子目錄名稱\n",
    "files = listdir(mypath)\n",
    "# 以迴圈處理\n",
    "j=0\n",
    "size = 28\n",
    "for i,f in enumerate(files):\n",
    "    # 產生檔案的絕對路徑\n",
    "    fullpath = join(mypath, f)\n",
    "    #print(f)\n",
    "    # 判斷 fullpath 是檔案還是目錄\n",
    "    ro = False\n",
    "    if isfile(fullpath):\n",
    "        im = cv2.imread(fullpath,0)\n",
    "        image = cv2.imread(fullpath)\n",
    "        img_merge[j%20*28:j%20*28+28,j//20*28: j//20*28+28]=im\n",
    "        retval, im_bin = cv2.threshold(im,215, 255, cv2.THRESH_BINARY_INV)\n",
    "        retval, labels,stats,centroids = cv2.connectedComponentsWithStats(im_bin)\n",
    "        x,y,w,h,area=stats[1]\n",
    "        cx,cy = centroids[1]\n",
    "\n",
    "        if w<5:\n",
    "            x=math.ceil(cx-3)\n",
    "            w=w+4\n",
    "        if h<5 :\n",
    "            y=math.ceil(cy-3)\n",
    "            h=h+6\n",
    "        if w > h+1 and w >10 :\n",
    "            #ro= True\n",
    "            img = rotate(im,90)\n",
    "            crop_img = img[x-1:x+w+1,y-1:y+h+1]\n",
    "        else:\n",
    "            crop_img = im[y:y+h,x:x+w]\n",
    "        im_h ,im_w= crop_img.shape\n",
    "        r = int(min(24/im_w,24/im_h))\n",
    "        if r<=0: r=1\n",
    "        if r>=4:r=2\n",
    "        crop_img = cv2.resize(crop_img,(im_w*r,im_h*r),interpolation=cv2.INTER_AREA)#interpolation=cv2.INTER_NEAREST\n",
    "        im_h ,im_w= crop_img.shape\n",
    "        u = int((size-im_h)/2)\n",
    "        v = int((size-im_w)/2)\n",
    "        crop_img = cv2.copyMakeBorder(crop_img,u,size-im_h-u,v,size-im_w-v, cv2.BORDER_CONSTANT,value=[255,255,255])\n",
    "        crop_img = cv2.erode(crop_img,(3,3), iterations=1)\n",
    "        #cv2.imwrite('./Desktop/new/'+f,crop_img)\n",
    "        \n",
    "        img = np.array(crop_img,dtype=np.float32).reshape(28*28)\n",
    "        img_set[j,:]=1-img/255\n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-c9492ad60e88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# define placeholder for inputs to network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mxs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255.\u001b[0m \u001b[1;31m#28*28=784\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mkeep_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#-1不論輸入資料維度，28*28資料像素，通道只有1是黑白\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "# define placeholder for inputs to network\n",
    "xs=tf.placeholder(tf.float32,[None,784])/255. #28*28=784\n",
    "ys=tf.placeholder(tf.float32,[None,10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "x_image = tf.reshape(xs,[-1,28,28,1]) #-1不論輸入資料維度，28*28資料像素，通道只有1是黑白\n",
    "#print(x_image.shape) #[n_sample,28,28,1]\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 5*1e-4\n",
    "num_steps = 1500\n",
    "batch_size = 150\n",
    "display_step = 100\n",
    "model_path = \"my_project/save_net.ckpt\"\n",
    "\n",
    "#def network(x_image,learning_rate,num_steps,batch_size,display_step,model_path):\n",
    "##conv1 layer##\n",
    "W_conv1=weight_variable([5,5,1,32]) #patch 5*5,in size 厚度 1,out size 32\n",
    "b_conv1=bias_variable([32])\n",
    "#print(W_conv1)\n",
    "#print(b_conv1)\n",
    "hid_conv1 = tf.nn.relu(conv2d(x_image,W_conv1)+b_conv1) #output size 28*28*32\n",
    "hid_pool1 =max_pool_2x2(hid_conv1)  #output size 14*14*32\n",
    "\n",
    "##conv2 layer##\n",
    "W_conv2=weight_variable([5,5,32,64]) #patch 5*5,in size 厚度 32(前一層來),out size 64\n",
    "b_conv2=bias_variable([64])\n",
    "hid_conv2 = tf.nn.relu(conv2d(hid_pool1,W_conv2)+b_conv2) #output size 7*7*64\n",
    "hid_pool2 =max_pool_2x2(hid_conv2)  #output size 7*7*64\n",
    "\n",
    "##func1 layer##\n",
    "W_fc1 = weight_variable([7*7*64,1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "#[n_samples,7,7,64]->>[n_samples,7*7*64]\n",
    "hid_pool2_flat = tf.reshape(hid_pool2,[-1,7*7*64])\n",
    "hid_fc1 = tf.nn.relu(tf.matmul(hid_pool2_flat,W_fc1)+b_fc1)\n",
    "hid_fc1_drop = tf.nn.dropout(hid_fc1,keep_prob)\n",
    "\n",
    "##func2 layer##\n",
    "W_fc2 = weight_variable([1024,10]) #output 有10種\n",
    "b_fc2 = bias_variable([10]) \n",
    "y_conv = tf.matmul(hid_fc1_drop, W_fc2) + b_fc2\n",
    "prediction = tf.nn.softmax(y_conv)\n",
    "#    return prediction\n",
    "\n",
    "\n",
    "#prediction = network(x_image,learning_rate,num_steps,batch_size,display_step,model_path)\n",
    "##the error between prediction and real data##\n",
    "#tf.reduce_sum(ys*tf.log(prediction))\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=ys, logits=prediction)) #loss\n",
    "#tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cross_entropy) \n",
    "#這樣的系統，需要AdamOptimizer來優化，且需較小的learning rate=0.0001\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(ys, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "tStart = time.time()#計時開始\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(num_steps+1):\n",
    "        batch_xs,batch_ys= mnist.train.next_batch(batch_size)\n",
    "        sess.run(train_step,feed_dict={xs:batch_xs,ys:batch_ys, keep_prob: 0.5})\n",
    "        if i%display_step==0 or i==num_steps:\n",
    "            train_accuracy = compute_accuracy(mnist.test.images,mnist.test.labels)\n",
    "            print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    #print(batch_xs)        \n",
    "    tEnd = time.time()#計時結束\n",
    "    save_path = saver.save(sess, model_path)\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "    \n",
    "print(\"It cost %f sec\" % (tEnd - tStart))#會自動做近位        \n",
    "#print(\"test accuracy %g\"%accuracy.eval(feed_dict={xs:batch_xs,ys:batch_ys, keep_prob: 1.0}))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from my_project/save_net.ckpt\n",
      "Testing Accuracy: 0.67\n",
      "[7 2 8 8 1 8 3 4 4 5 5 6 6 3 2 2 1 1 0 0 2 6 8 8 2 3 3 8 4 5 5 6 6 0 3 3 1\n",
      " 2 4 3 0 0 1 1 7 2 3 6 6 5 5 9 4 3 9 9 8 8 8 0 3 6 3 6 7 9 3 2 2 8 8 8 8 4\n",
      " 0 0 4 7 7 3 0 6 3 4 6 2 8 5 2 8 8 1 8 4 1 1 7 8 0 8 8 7 8 8 4 8 4 8 4 4 4\n",
      " 8 0 2 1 6 8 1 1 8 7 4 3 0 3 8 7 6 3 2 2 3 3 8 5 6 6 4 9 8 8 8 8 8 8 8 8 8\n",
      " 8 7 7 8 8 6 6 5 5 4 4 3 3 2 2 1 1 1 0 0 1 6 6 2 4 9 5 2 1 5 8 8 4 1 3 8 7\n",
      " 7 3 3 5 3 1 3 6 2 3 7 2 3 3 7]\n"
     ]
    }
   ],
   "source": [
    "model_path = \"my_project/save_net.ckpt\"\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session(graph=tf.get_default_graph()) as sess:\n",
    "    sess.run(init)\n",
    "    saver = tf.train.import_meta_graph(model_path+'.meta')\n",
    "    saver.restore(sess,tf.train.latest_checkpoint(\"my_project/\"))\n",
    "    prediction_result = sess.run(tf.argmax(prediction, 1),feed_dict={xs:img_set, keep_prob: 1})\n",
    "\n",
    "    print(\"Testing Accuracy:\",compute_accuracy(img_set,y_r))\n",
    "    #for i,img in enumerate()  \n",
    "    print(prediction_result)\n",
    "    #將結果寫入csv\n",
    "    #dataframe = pd.DataFrame(prediction_result)\n",
    "    #dataframe.to_csv(\"pre.csv\",index=False,header=False)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
