{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def Vertical(image, axis=0):\n",
    "    vertical_sum = np.sum(image, axis=0)\n",
    "    return vertical_sum\n",
    "        \n",
    "def Horizontal(image, axis=1):\n",
    "    horizontal_sum = np.sum(image, axis=1)\n",
    "    return horizontal_sum\n",
    "\n",
    "def extract_peek_ranges_from_array(array_vals, minimun_val, minimun_range):\n",
    "    start_i = None\n",
    "    end_i = None\n",
    "    peek_ranges = []\n",
    "    #enumerate() 函數用於將數據對象組合為一個索引序列，同時列出數據和數據下標\n",
    "    for i, val in enumerate(array_vals):\n",
    "        if val > minimun_val and start_i is None:\n",
    "            start_i = i\n",
    "        elif val > minimun_val and start_i is not None:\n",
    "            pass\n",
    "        elif val < minimun_val and start_i is not None:\n",
    "            end_i = i\n",
    "            if end_i - start_i >= minimun_range:\n",
    "                peek_ranges.append((start_i, end_i))\n",
    "            start_i = None\n",
    "            end_i = None\n",
    "        elif val < minimun_val and start_i is None:\n",
    "            pass\n",
    "        # else:\n",
    "            # raise ValueError(\"cannot parse this case...\")\n",
    "    return peek_ranges\n",
    "def saperate_by_space(array_vals, space_size, minimun_val):    \n",
    "    start_i = None\n",
    "    end_i = None\n",
    "    peek_ranges = []\n",
    "    space_counter = 0\n",
    "\n",
    "    for i, val in enumerate(array_vals):                 \n",
    "        if val > minimun_val and start_i is None:\n",
    "            start_i = i\n",
    "        elif val > minimun_val and start_i is not None:\n",
    "            space_counter = 0\n",
    "            if i is len(array_vals) -1:\n",
    "                peek_ranges.append((start_i, i))\n",
    "            end_i = None\n",
    "\n",
    "        elif val < minimun_val and start_i is not None:\n",
    "            if space_counter is 0:\n",
    "                end_i = i;\n",
    "            space_counter = space_counter + 1\n",
    "\n",
    "            \n",
    "            if space_counter is space_size :\n",
    "                peek_ranges.append((start_i, end_i))\n",
    "                start_i = None\n",
    "                end_i = None\n",
    "        elif val < minimun_val and start_i is None:\n",
    "            pass\n",
    "        #else:\n",
    "        #    raise ValueError(\"cannot parse this case...\")\n",
    "    return peek_ranges\n",
    "def adj_img(img_path,size = 28):\n",
    "    im = cv2.imread(img_path,0)\n",
    "    im = cv2.medianBlur(im, 3)\n",
    "    #im = cv2.GaussianBlur(im,(3,3),0)\n",
    "    #im = cv2.erode(im,(2,2), iterations=1)\n",
    "    retval, im_bin = cv2.threshold(im,210, 255, cv2.THRESH_BINARY_INV)#黑底白字\n",
    "    \n",
    "    hor_sum = Horizontal(im_bin)/255\n",
    "    ver_sum= Vertical(im_bin)/255\n",
    "    #print(hor_sum)\n",
    "    #print(ver_sum)\n",
    "    #print(extract_peek_ranges_from_array(hor_sum, minimun_val=2, minimun_range=1))\n",
    "    hor = extract_peek_ranges_from_array(hor_sum, minimun_val=0.8, minimun_range=2)\n",
    "    ver = extract_peek_ranges_from_array(ver_sum, minimun_val=0.8, minimun_range=2)\n",
    "    print(hor,'@',ver)\n",
    "    \n",
    "    if len(hor)<1:\n",
    "        (y1,y2) = (1,28)\n",
    "    elif len(hor)==3:\n",
    "        (y1,y2)=hor[1]\n",
    "    elif len(hor)==2:\n",
    "        y1=hor[0][1]\n",
    "        y2=hor[0][0]\n",
    "    else:  \n",
    "        (y1,y2)=hor[0]\n",
    "        \n",
    "    if len(ver)<1:\n",
    "        (x1,x2) = (1,28)\n",
    "    elif len(ver)==3:\n",
    "        (x1,x2)=ver[1]\n",
    "    elif len(ver)==2:\n",
    "        x1=ver[0][1]\n",
    "        x2=ver[0][0]\n",
    "    else:  \n",
    "        (x1,x2)=ver[0]\n",
    "\n",
    "    #x1,x2,y1,y2 = min(X),max(X),min(Y),max(Y)\n",
    "    if x2-x1==0 or y2-y1==0:\n",
    "        crop_img = im\n",
    "    else: \n",
    "        crop_img = im[y1:y2,x1:x2]\n",
    "    im_h ,im_w= crop_img.shape\n",
    "    r = int(min(24/im_w,24/im_h))\n",
    "    if r<=0: r=1\n",
    "    if r>=4:r=2\n",
    "    crop_img = cv2.resize(crop_img,(im_w*r,im_h*r),interpolation=cv2.INTER_AREA)#interpolation=cv2.INTER_NEAREST\n",
    "    im_h ,im_w= crop_img.shape\n",
    "    u = int((size-im_h)/2)\n",
    "    v = int((size-im_w)/2)\n",
    "    crop_img = cv2.copyMakeBorder(crop_img,u,size-im_h-u,v,size-im_w-v, cv2.BORDER_CONSTANT,value=[255,255,255])\n",
    "    crop_img = cv2.erode(crop_img,(3,3), iterations=1)\n",
    "    return crop_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNSIT_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNSIT_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNSIT_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNSIT_data\\t10k-labels-idx1-ubyte.gz\n",
      "Extracting MNSIT_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNSIT_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNSIT_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNSIT_data\\t10k-labels-idx1-ubyte.gz\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, isdir, join\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import math\n",
    "#import argparse\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNSIT_data',one_hot=True)\n",
    "\n",
    "def rotate(image, angle, center=None, scale=1.0):\n",
    "    # 獲取圖像尺寸\n",
    "    (h, w) = image.shape[:2]\n",
    "    # 若未指定旋轉中心，则將圖像中心設為旋轉中心\n",
    "    if center is None:\n",
    "        center = (w / 2, h / 2)\n",
    "    # 執行旋轉\n",
    "    M = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h))\n",
    "    # 返回旋轉後的圖像\n",
    "    return rotated\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNSIT_data',one_hot=True)\n",
    "\n",
    "def compute_accuracy(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction, feed_dict={xs: v_xs, keep_prob: 1})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    result = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys, keep_prob: 1})\n",
    "    return result\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1) #類似normal分布，產生隨機變量\n",
    "    return tf.Variable(initial)\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "def conv2d(x,W):\n",
    "    #stride [1,x_movement,y_movement,1],頭尾一定都是1\n",
    "    #Must have strides[0]=strides[3]=1\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding = 'SAME') \n",
    "def max_pool_2x2(x):\n",
    "    #stride [1,x_movement,y_movement,1]\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "batch_size = 150\n",
    "batch_xs,batch_ys= mnist.train.next_batch(batch_size)\n",
    "print(batch_xs)\n",
    "print(batch_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##將cvs裡面答案轉為陣列\n",
    "df = pd.read_csv('validation.csv',header=None)  \n",
    "df = df.T\n",
    "df_temp = pd.get_dummies(df[0]) #One-hot編碼\n",
    "y_r = np.array(df_temp)\n",
    "##將驗證圖片讀檔，二值化並存成2維陣列200*(784)\n",
    "img_set = np.zeros((200,28*28))\n",
    "# 指定要列出所有檔案的目錄\n",
    "mypath = \"./validation\"\n",
    "# 取得所有檔案與子目錄名稱\n",
    "files = listdir(mypath)\n",
    "# 以迴圈處理\n",
    "j=0\n",
    "size = 28\n",
    "for i,f in enumerate(files):\n",
    "    # 產生檔案的絕對路徑\n",
    "    fullpath = join(mypath, f)\n",
    "    #print(f)\n",
    "    # 判斷 fullpath 是檔案還是目錄\n",
    "    ro = False\n",
    "    if isfile(fullpath):\n",
    "        im = cv2.imread(fullpath,0)\n",
    "        image = cv2.imread(fullpath)\n",
    "        retval, im_bin = cv2.threshold(im,215, 255, cv2.THRESH_BINARY_INV)\n",
    "        retval, labels,stats,centroids = cv2.connectedComponentsWithStats(im_bin)\n",
    "        #for stat in stats:\n",
    "        x,y,w,h,area=stats[1]\n",
    "        cx,cy = centroids[1]\n",
    "        #draw_img = cv2.rectangle(image, (x-1,y-1), (x+w+1,y+h+1), (0,0,255),1, 8, 0)\n",
    "        #cv2.imwrite('./Desktop/new/draw_'+f,draw_img)\n",
    "        if w<5:\n",
    "            x=math.ceil(cx-3)\n",
    "            w=w+4\n",
    "        if h<5 :\n",
    "            y=math.ceil(cy-3)\n",
    "            h=h+6\n",
    "        if w > h+1 and w >10 :\n",
    "            #ro= True\n",
    "            img = rotate(im,90)\n",
    "            crop_img = img[x-1:x+w+1,y-1:y+h+1]\n",
    "        else:\n",
    "            crop_img = im[y:y+h,x:x+w]\n",
    "        im_h ,im_w= crop_img.shape\n",
    "        r = int(min(24/im_w,24/im_h))\n",
    "        if r<=0: r=1\n",
    "        if r>=4:r=2\n",
    "        crop_img = cv2.resize(crop_img,(im_w*r,im_h*r),interpolation=cv2.INTER_AREA)#interpolation=cv2.INTER_NEAREST\n",
    "        im_h ,im_w= crop_img.shape\n",
    "        u = int((size-im_h)/2)\n",
    "        v = int((size-im_w)/2)\n",
    "        crop_img = cv2.copyMakeBorder(crop_img,u,size-im_h-u,v,size-im_w-v, cv2.BORDER_CONSTANT,value=[255,255,255])\n",
    "        crop_img = cv2.erode(crop_img,(3,3), iterations=1)\n",
    "        cv2.imwrite('./Desktop/new/'+f,crop_img)\n",
    "        img = np.array(crop_img,dtype=np.float32).reshape(28*28)\n",
    "        img_set[j,:]=1-img/255\n",
    "        j+=1\n",
    "        #print(img)\n",
    "#print(img_set)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "im = cv2.imread('./validation/006.jpg',0)\n",
    "retval, im_bin = cv2.threshold(im , 200, 255, cv2.THRESH_BINARY_INV)#反轉黑底白字\n",
    "#print(im_bin)\n",
    "#retval2, im_bin2= cv2.threshold(255-im*0.8, 100, 255, cv2.THRESH_TOZERO)\n",
    "image ,contours,hierarchy = cv2.findContours(im_bin,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "X = []\n",
    "Y = []\n",
    "print(contours)\n",
    "for i in contours[1]:\n",
    "    print(i)\n",
    "    x = i[0][0]\n",
    "    y = i[0][1]\n",
    "    X.append(x)\n",
    "    Y.append(y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#將圖片填補空白成size*size\n",
    "size =28\n",
    "\"\"\"\n",
    "# im:opencv 開啟圖片,fullpath 字元圖片儲存路徑\n",
    "def fill_blank(mypath):\n",
    "    global size\n",
    "    im = cv2.imread(fullpath,0)\n",
    "    #print(im)      \n",
    "    retval, im_bin = cv2.threshold(im, 127, 255, cv2.THRESH_BINARY_INV) \n",
    "    im_h ,im_w= im.shape\n",
    "    u = int((size-im_h)/2)\n",
    "    v = int((size-im_w)/2)\n",
    "    im = cv2.copyMakeBorder(im,u,size-im_h-u,v,size-im_w-v, cv2.BORDER_CONSTANT,value=[255,255,255])\n",
    "    cv2.imwrite(fullpath, im)\n",
    "    return im\n",
    "#將圖片校正(找出文字中心，對物件縮放去掉多餘空白)\n",
    "def adj_img(fullpath,size = 28):\n",
    "    im = cv2.imread(fullpath,0)\n",
    "    retval, im_bin = cv2.threshold(im,200, 255, cv2.THRESH_BINARY_INV)#黑底白字\n",
    "    retval2, im_bin2= cv2.threshold(255-im*0.8,100, 255, cv2.THRESH_TOZERO)\n",
    "    image ,contours,hierarchy = cv2.findContours(im_bin,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in contours[0]:\n",
    "        x = i[0][0]\n",
    "        y = i[0][1]\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    x1,x2,y1,y2 = min(X),max(X),min(Y),max(Y)\n",
    "    crop_img = im_bin2[y1-3:y2+3,x1-3:x2+3]\n",
    "    im_w ,im_h= crop_img.shape\n",
    "    r = int(min(24/im_w,24/im_h))\n",
    "    if r<0: r=1\n",
    "    if r>=4:r=3\n",
    "    crop_img = cv2.resize(crop_img,(im_w*r,im_h*r))#interpolation=cv2.INTER_NEAREST\n",
    "    im_h ,im_w= crop_img.shape\n",
    "    u = int((size-im_h)/2)\n",
    "    v = int((size-im_w)/2)\n",
    "    crop_img = cv2.copyMakeBorder(crop_img,u,size-im_h-u,v,size-im_w-v, cv2.BORDER_CONSTANT,value=[0,0,0])\n",
    "    return crop_img\n",
    "\n",
    "\n",
    "#img = np.array(im_bin/255,dtype=np.float32).reshape(28*28)\n",
    "#im_h ,im_w= im.shape\n",
    "#u = int((size-im_h)/2)\n",
    "#v = int((size-im_w)/2)\n",
    "#im = cv2.copyMakeBorder(im,u,size-im_h-u,v,size-im_w-v, cv2.BORDER_CONSTANT,value=[255,255,255])\n",
    "#cv2.imwrite(fullpath, im)    \n",
    "\n",
    "  \n",
    "\"\"\"\n",
    "img_path ='C:/Users/user/validation/045.jpg' \n",
    "im = cv2.imread(img_path,0)\n",
    "#im = cv2.fastNlMeansDenoising(im,None,5,5,3,15)\n",
    "im = cv2.GaussianBlur(im,(3,3),0)\n",
    "#im = cv2.erode(im,(2,2), iterations=1)\n",
    "retval, im_bin = cv2.threshold(im,200, 255, cv2.THRESH_BINARY_INV)#黑底白字\n",
    "cv2.imwrite('C:/Users/user/Desktop/045-3.jpg',im_bin)\n",
    "hor_sum = Horizontal(im_bin)/255\n",
    "ver_sum= Vertical(im_bin)/255\n",
    "#print(hor_sum)\n",
    "#print(ver_sum)\n",
    "#print(extract_peek_ranges_from_array(hor_sum, minimun_val=2, minimun_range=1))\n",
    "hor = extract_peek_ranges_from_array(hor_sum, minimun_val=0.8, minimun_range=2)\n",
    "ver = extract_peek_ranges_from_array(ver_sum, minimun_val=0.8, minimun_range=2)\n",
    "print(hor,'@',ver)\n",
    "\n",
    "if len(hor)<1:\n",
    "    (y1,y2) = (1,28)\n",
    "elif len(hor)==3:\n",
    "    (y1,y2)=hor[1]\n",
    "elif len(hor)==2:\n",
    "    y1=hor[0][1]\n",
    "    y2=hor[0][0]\n",
    "else:  \n",
    "    (y1,y2)=hor[0]\n",
    "\n",
    "if len(ver)<1:\n",
    "    (x1,x2) = (1,28)\n",
    "elif len(ver)==3:\n",
    "    (x1,x2)=ver[1]\n",
    "elif len(ver)==2:\n",
    "    x1=ver[0][1]\n",
    "    x2=ver[0][0]\n",
    "else:  \n",
    "    (x1,x2)=ver[0]\n",
    "\n",
    "#x1,x2,y1,y2 = min(X),max(X),min(Y),max(Y)\n",
    "if x2-x1==0 or y2-y1==0:\n",
    "    crop_img = im\n",
    "else: \n",
    "    crop_img = im[y1:y2,x1:x2]\n",
    "im_h ,im_w= crop_img.shape\n",
    "r = int(min(24/im_w,24/im_h))\n",
    "if r<=0: r=1\n",
    "if r>=4:r=2\n",
    "crop_img = cv2.resize(crop_img,(im_w*r,im_h*r),interpolation=cv2.INTER_AREA)#interpolation=cv2.INTER_NEAREST\n",
    "im_h ,im_w= crop_img.shape\n",
    "\n",
    "u = int((size-im_h)/2)\n",
    "v = int((size-im_w)/2)\n",
    "crop_img = cv2.copyMakeBorder(crop_img,u,size-im_h-u,v,size-im_w-v, cv2.BORDER_CONSTANT,value=[255,255,255])\n",
    "crop_img = cv2.erode(crop_img,(3,3), iterations=1)\n",
    "\n",
    "cv2.imwrite('C:/Users/user/Desktop/045.jpg', crop_img) \n",
    "\n",
    "#img_path ='C:/Users/user/validation/045.jpg' \n",
    "#erosion = adj_img(img_path)\n",
    "#cv2.imwrite('C:/Users/user/Desktop/044.jpg', erosion) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##將驗證圖片讀檔，二值化並存成3維陣列28*28*200\n",
    "img_set = np.zeros((200,28*28))\n",
    "# 指定要列出所有檔案的目錄\n",
    "mypath = \"./validation\"\n",
    "# 取得所有檔案與子目錄名稱\n",
    "files = listdir(mypath)\n",
    "# 以迴圈處理\n",
    "for i,f in enumerate(files):\n",
    "  # 產生檔案的絕對路徑\n",
    "  fullpath = join(mypath, f)\n",
    "  # 判斷 fullpath 是檔案還是目錄\n",
    "  if isfile(fullpath):\n",
    "    #im = cv2.imread(fullpath)\n",
    "    #retval, im_bin = cv2.threshold(im, 127, 255, cv2.THRESH_BINARY_INV) \n",
    "    #img = np.array(im,dtype=np.float32).reshape(28*28)\n",
    "    \n",
    "    img = Image.open(fullpath)\n",
    "    #img = img.convert('1')\n",
    "    img_array = 1-np.array(img,dtype=np.float32).reshape(28*28)/255\n",
    "    #img_set[i,:]=img\n",
    "    #print(img)\n",
    "print(img_array)\n",
    "#print(img_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNSIT_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNSIT_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNSIT_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNSIT_data\\t10k-labels-idx1-ubyte.gz\n",
      "step 0, training accuracy 0.1224\n",
      "step 100, training accuracy 0.7117\n",
      "step 200, training accuracy 0.9486\n",
      "step 300, training accuracy 0.9645\n",
      "step 400, training accuracy 0.9728\n",
      "step 500, training accuracy 0.9775\n",
      "step 600, training accuracy 0.9786\n",
      "step 700, training accuracy 0.9794\n",
      "step 800, training accuracy 0.9791\n",
      "step 900, training accuracy 0.9826\n",
      "step 1000, training accuracy 0.9838\n",
      "step 1100, training accuracy 0.9864\n",
      "step 1200, training accuracy 0.9873\n",
      "step 1300, training accuracy 0.9867\n",
      "step 1400, training accuracy 0.9859\n",
      "step 1500, training accuracy 0.9879\n",
      "Model saved in file: my_project/save_net.ckpt\n",
      "It cost 1028.952853 sec\n"
     ]
    }
   ],
   "source": [
    "# define placeholder for inputs to network\n",
    "xs=tf.placeholder(tf.float32,[None,784])/255. #28*28=784\n",
    "ys=tf.placeholder(tf.float32,[None,10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "x_image = tf.reshape(xs,[-1,28,28,1]) #-1不論輸入資料維度，28*28資料像素，通道只有1是黑白\n",
    "#print(x_image.shape) #[n_sample,28,28,1]\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 5*1e-4\n",
    "num_steps = 1500\n",
    "batch_size = 150\n",
    "display_step = 100\n",
    "model_path = \"my_project/save_net.ckpt\"\n",
    "\n",
    "#def network(x_image,learning_rate,num_steps,batch_size,display_step,model_path):\n",
    "##conv1 layer##\n",
    "W_conv1=weight_variable([5,5,1,32]) #patch 5*5,in size 厚度 1,out size 32\n",
    "b_conv1=bias_variable([32])\n",
    "#print(W_conv1)\n",
    "#print(b_conv1)\n",
    "hid_conv1 = tf.nn.relu(conv2d(x_image,W_conv1)+b_conv1) #output size 28*28*32\n",
    "hid_pool1 =max_pool_2x2(hid_conv1)  #output size 14*14*32\n",
    "\n",
    "##conv2 layer##\n",
    "W_conv2=weight_variable([5,5,32,64]) #patch 5*5,in size 厚度 32(前一層來),out size 64\n",
    "b_conv2=bias_variable([64])\n",
    "hid_conv2 = tf.nn.relu(conv2d(hid_pool1,W_conv2)+b_conv2) #output size 7*7*64\n",
    "hid_pool2 =max_pool_2x2(hid_conv2)  #output size 7*7*64\n",
    "\n",
    "##func1 layer##\n",
    "W_fc1 = weight_variable([7*7*64,1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "#[n_samples,7,7,64]->>[n_samples,7*7*64]\n",
    "hid_pool2_flat = tf.reshape(hid_pool2,[-1,7*7*64])\n",
    "hid_fc1 = tf.nn.relu(tf.matmul(hid_pool2_flat,W_fc1)+b_fc1)\n",
    "hid_fc1_drop = tf.nn.dropout(hid_fc1,keep_prob)\n",
    "\n",
    "##func2 layer##\n",
    "W_fc2 = weight_variable([1024,10]) #output 有10種\n",
    "b_fc2 = bias_variable([10]) \n",
    "y_conv = tf.matmul(hid_fc1_drop, W_fc2) + b_fc2\n",
    "prediction = tf.nn.softmax(y_conv)\n",
    "#    return prediction\n",
    "\n",
    "\n",
    "#prediction = network(x_image,learning_rate,num_steps,batch_size,display_step,model_path)\n",
    "##the error between prediction and real data##\n",
    "#tf.reduce_sum(ys*tf.log(prediction))\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=ys, logits=prediction)) #loss\n",
    "#tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cross_entropy) \n",
    "#這樣的系統，需要AdamOptimizer來優化，且需較小的learning rate=0.0001\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(ys, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "tStart = time.time()#計時開始\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(num_steps+1):\n",
    "        batch_xs,batch_ys= mnist.train.next_batch(batch_size)\n",
    "        sess.run(train_step,feed_dict={xs:batch_xs,ys:batch_ys, keep_prob: 0.5})\n",
    "        if i%display_step==0 or i==num_steps:\n",
    "            train_accuracy = compute_accuracy(mnist.test.images,mnist.test.labels)\n",
    "            print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    #print(batch_xs)        \n",
    "    tEnd = time.time()#計時結束\n",
    "    save_path = saver.save(sess, model_path)\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "    \n",
    "print(\"It cost %f sec\" % (tEnd - tStart))#會自動做近位        \n",
    "#print(\"test accuracy %g\"%accuracy.eval(feed_dict={xs:batch_xs,ys:batch_ys, keep_prob: 1.0}))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.labels[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.placeholder(tf.float32,[None,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from my_project/save_net.ckpt\n",
      "Testing Accuracy: 0.67\n",
      "[7 2 8 8 1 8 3 4 4 5 5 6 6 3 2 2 1 1 0 0 2 6 8 8 2 3 3 8 4 5 5 6 6 0 3 3 1\n",
      " 2 4 3 0 0 1 1 7 2 3 6 6 5 5 9 4 3 9 9 8 8 8 0 3 6 3 6 7 9 3 2 2 8 8 8 8 4\n",
      " 0 0 4 7 7 3 0 6 3 4 6 2 8 5 2 8 8 1 8 4 1 1 7 8 0 8 8 7 8 8 4 8 4 8 4 4 4\n",
      " 8 0 2 1 6 8 1 1 8 7 4 3 0 3 8 7 6 3 2 2 3 3 8 5 6 6 4 9 8 8 8 8 8 8 8 8 8\n",
      " 8 7 7 8 8 6 6 5 5 4 4 3 3 2 2 1 1 1 0 0 1 6 6 2 4 9 5 2 1 5 8 8 4 1 3 8 7\n",
      " 7 3 3 5 3 1 3 6 2 3 7 2 3 3 7]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "with tf.Graph().as_default():\n",
    "    #np.set_printoptions(threshold=np.inf)\n",
    "    xs=tf.placeholder(tf.float32,[None,784])/255. #28*28=784\n",
    "    ys=tf.placeholder(tf.float32,[None,10])\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    x_image = tf.reshape(xs,[-1,28,28,1]) #-1不論輸入資料維度，28*28資料像素，通道只有1是黑白\n",
    "    #print(x_image.shape) #[n_sample,28,28,1]\n",
    "\n",
    "    # Parameters\n",
    "    learning_rate = 1e-4\n",
    "    num_steps = 2000\n",
    "    batch_size = 200\n",
    "    display_step = 100\n",
    "    model_path = \"my_project/save_net.ckpt\"\n",
    "\n",
    "    #def network(x_image):\n",
    "        #global learning_rate,num_steps,batch_size,display_step,model_path\n",
    "    ##conv1 layer##\n",
    "    W_conv1=weight_variable([5,5,1,32]) #patch 5*5,in size 厚度 1,out size 32\n",
    "    b_conv1=bias_variable([32])\n",
    "    #print(W_conv1)\n",
    "    #print(b_conv1)\n",
    "    hid_conv1 = tf.nn.relu(conv2d(x_image,W_conv1)+b_conv1) #output size 28*28*32\n",
    "    hid_pool1 =max_pool_2x2(hid_conv1)  #output size 14*14*32\n",
    "\n",
    "    ##conv2 layer##\n",
    "    W_conv2=weight_variable([5,5,32,64]) #patch 5*5,in size 厚度 32(前一層來),out size 64\n",
    "    b_conv2=bias_variable([64])\n",
    "    hid_conv2 = tf.nn.relu(conv2d(hid_pool1,W_conv2)+b_conv2) #output size 14*14*64\n",
    "    hid_pool2 =max_pool_2x2(hid_conv2)  #output size 7*7*64\n",
    "\n",
    "    ##func1 layer##\n",
    "    W_fc1 = weight_variable([7*7*64,1024])\n",
    "    b_fc1 = bias_variable([1024])\n",
    "    #[n_samples,7,7,64]->>[n_samples,7*7*64]\n",
    "    hid_pool2_flat = tf.reshape(hid_pool2,[-1,7*7*64])\n",
    "    hid_fc1 = tf.nn.relu(tf.matmul(hid_pool2_flat,W_fc1)+b_fc1)\n",
    "    hid_fc1_drop = tf.nn.dropout(hid_fc1,keep_prob)\n",
    "\n",
    "    ##func2 layer##\n",
    "    W_fc2 = weight_variable([1024,10]) #output 有10種\n",
    "    b_fc2 = bias_variable([10]) \n",
    "    y_conv = tf.matmul(hid_fc1_drop, W_fc2) + b_fc2\n",
    "    prediction = tf.nn.softmax(y_conv)\n",
    "    #    return prediction\n",
    "    #prediction = network(x_image)\n",
    "\n",
    "    ##the error between prediction and real data##\n",
    "    #tf.reduce_sum(ys*tf.log(prediction))\n",
    "    #cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=ys, logits=prediction)) #loss\n",
    "    #tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "    #train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cross_entropy) \n",
    "\n",
    "    # Evaluate model\n",
    "    correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(ys, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "    #print(img_set)\n",
    "    #tf.reset_default_graph()\n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        model_path = \"my_project/save_net.ckpt\"\n",
    "        sess.run(init)\n",
    "        saver = tf.train.import_meta_graph(model_path+'.meta')\n",
    "        saver.restore(sess,tf.train.latest_checkpoint(\"my_project/\"))\n",
    "        prediction_result = sess.run(tf.argmax(prediction, 1),feed_dict={xs:img_set, keep_prob: 1})\n",
    "\n",
    "        print(\"Testing Accuracy:\",compute_accuracy(img_set,y_r))\n",
    "        #for i,img in enumerate()  \n",
    "        print(prediction_result)\n",
    "    \n",
    "    \n",
    "xs=tf.placeholder(tf.float32,[None,784])/255. #28*28=784\n",
    "ys=tf.placeholder(tf.float32,[None,10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "x_image = tf.reshape(xs,[-1,28,28,1]) #-1不論輸入資料維度，28*28資料像素，通道只有1是黑白\n",
    "#print(x_image.shape) #[n_sample,28,28,1]\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 1e-4\n",
    "num_steps = 2000\n",
    "batch_size = 200\n",
    "display_step = 100\n",
    "model_path = \"my_project/save_net.ckpt\"\n",
    "\n",
    "#def network(x_image):\n",
    "    #global learning_rate,num_steps,batch_size,display_step,model_path\n",
    "##conv1 layer##\n",
    "W_conv1=weight_variable([5,5,1,32]) #patch 5*5,in size 厚度 1,out size 32\n",
    "b_conv1=bias_variable([32])\n",
    "#print(W_conv1)\n",
    "#print(b_conv1)\n",
    "hid_conv1 = tf.nn.relu(conv2d(x_image,W_conv1)+b_conv1) #output size 28*28*32\n",
    "hid_pool1 =max_pool_2x2(hid_conv1)  #output size 14*14*32\n",
    "\n",
    "##conv2 layer##\n",
    "W_conv2=weight_variable([5,5,32,64]) #patch 5*5,in size 厚度 32(前一層來),out size 64\n",
    "b_conv2=bias_variable([64])\n",
    "hid_conv2 = tf.nn.relu(conv2d(hid_pool1,W_conv2)+b_conv2) #output size 14*14*64\n",
    "hid_pool2 =max_pool_2x2(hid_conv2)  #output size 7*7*64\n",
    "\n",
    "##func1 layer##\n",
    "W_fc1 = weight_variable([7*7*64,1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "#[n_samples,7,7,64]->>[n_samples,7*7*64]\n",
    "hid_pool2_flat = tf.reshape(hid_pool2,[-1,7*7*64])\n",
    "hid_fc1 = tf.nn.relu(tf.matmul(hid_pool2_flat,W_fc1)+b_fc1)\n",
    "hid_fc1_drop = tf.nn.dropout(hid_fc1,keep_prob)\n",
    "\n",
    "##func2 layer##\n",
    "W_fc2 = weight_variable([1024,10]) #output 有10種\n",
    "b_fc2 = bias_variable([10]) \n",
    "y_conv = tf.matmul(hid_fc1_drop, W_fc2) + b_fc2\n",
    "prediction = tf.nn.softmax(y_conv)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(ys, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\"\"\"\n",
    "model_path = \"my_project/save_net.ckpt\"\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session(graph=tf.get_default_graph()) as sess:\n",
    "    sess.run(init)\n",
    "    saver = tf.train.import_meta_graph(model_path+'.meta')\n",
    "    saver.restore(sess,tf.train.latest_checkpoint(\"my_project/\"))\n",
    "    prediction_result = sess.run(tf.argmax(prediction, 1),feed_dict={xs:img_set, keep_prob: 1})\n",
    "\n",
    "    print(\"Testing Accuracy:\",compute_accuracy(img_set,y_r))\n",
    "    #for i,img in enumerate()  \n",
    "    print(prediction_result)\n",
    "    #將結果寫入csv\n",
    "    dataframe = pd.DataFrame(prediction_result)\n",
    "    dataframe.to_csv(\"pre.csv\",index=False,header=False)\n",
    "    #print(sess.run(tf.argmax(prediction, 1),feed_dict={xs:img_set, keep_prob: 1}))\n",
    "    #print(sess.run(prediction,feed_dict={xs:img_set}))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##the error between prediction and real data##\n",
    "prediction = network(x_image,learning_rate,num_steps,batch_size,display_step,model_path)\n",
    "cross_entropy = tf.reduce_mean(tf.reduce_sum(ys*tf.log(prediction))) #loss\n",
    "#tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cross_entropy) \n",
    "#這樣的系統，需要AdamOptimizer來優化，且需較小的learning rate=0.0001\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "tStart = time.time()#計時開始\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(num_steps):\n",
    "        batch_xs,batch_ys= mnist.train.next_batch(batch_size)\n",
    "        sess.run(train_step,feed_dict={xs:batch_xs,ys:batch_ys, keep_prob: 0.5})\n",
    "        if i%display_step==0 or i==num_steps:\n",
    "            loss, acc = sess.run([cross_entropy, accuracy], feed_dict={X: batch_xs,Y: batch_ys})\n",
    "            print(\"Step \" + str(i) + \", Minibatch Loss= \" + \"{:.4f}\".format(loss) + \\\n",
    "                  \", Training Accuracy= \" + \"{:.3f}\".format(acc))\n",
    "\n",
    "    tEnd = time.time()#計時結束\n",
    "    save_path = saver.save(sess, model_path)\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "    \n",
    "    print(\"Testing Accuracy:\",sess.run(accuracy, feed_dict={X:img_set,Y: y_r}))\n",
    "print(\"It cost %f sec\" % (tEnd - tStart))#會自動做近位        \n",
    "#print(\"test accuracy %g\"%accuracy.eval(feed_dict={xs:batch_xs,ys:batch_ys, keep_prob: 1.0}))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
